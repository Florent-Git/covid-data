{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-21T09:16:20.196892300Z",
     "start_time": "2024-01-21T09:16:20.114801800Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import utils as util\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report, RocCurveDisplay\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Preamble analysis of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-21T08:51:49.126307Z",
     "start_time": "2024-01-21T08:51:46.742060700Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./data/covid_data.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Analysing existing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-21T08:51:49.128408800Z",
     "start_time": "2024-01-21T08:51:48.524990600Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_null = df.copy()\n",
    "for i in [97, 98, 99]:\n",
    "   df_null.replace(i , np.nan, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-21T08:51:49.298779600Z",
     "start_time": "2024-01-21T08:51:49.110164400Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_null.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "As we can show with the following graph, there are **a lot** of NA values in the dataset. We will have to handle them.\n",
    "\n",
    "One approach is to take the mean of the column and replace the NA values with it. However, this is not a good approach, as it will skew the data. We will have to find a better way to handle the NA values.\n",
    "\n",
    "We will therefore have to go each problematic columun to fix the eventual problematic data\n",
    "\n",
    "Remember that in the dataset definition it says that 97,98 and 99 are null values, let's deal with that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-21T08:51:49.299749400Z",
     "start_time": "2024-01-21T08:51:49.234326500Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# sns.heatmap(df_null.isnull(), cbar=False)\n",
    "# plt.title('Before data cleanup', color = 'black', fontsize = 15)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### As we can see, that's no bueno..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-21T08:51:50.407412200Z",
     "start_time": "2024-01-21T08:51:49.247798200Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.describe().round(3).T.drop('count', axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Furthermore, we have some suspiciously skewed data. Is really half of the population pregnant?!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 1.2 Managing the DEAD people "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "People with a DATE_DIED value of 9999-99-99 simply aren't dead, so we'll just create a new DEAD column to represent that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-21T08:51:50.701367500Z",
     "start_time": "2024-01-21T08:51:50.527652800Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Check for any strings in the feature \"DATE_DIED\"\n",
    "df['DATE_DIED'][df['DATE_DIED'].apply(lambda x: isinstance(x, str))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-21T08:51:50.989218900Z",
     "start_time": "2024-01-21T08:51:50.621764Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['DEAD'] = [2 if i=='9999-99-99' else 1 for i in df.DATE_DIED]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-21T08:51:51.118687400Z",
     "start_time": "2024-01-21T08:51:51.005879Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['DEAD'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "We'll also replace 9999-99-99 with NaN for the time being"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-21T08:51:51.216011500Z",
     "start_time": "2024-01-21T08:51:51.039605500Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = df.drop('DATE_DIED', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### How does the data look now ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-21T08:51:53.013011300Z",
     "start_time": "2024-01-21T08:51:51.176572300Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.describe().round(3).T.drop('count', axis = 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Hmmm, it looks like we'll have to work on the PREGNANT, ICU, and INTUBED people"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 SEX Values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll just set the 1 and 2 values to \"Female\" and \"Male\" respectively"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 1.4 Pregnant values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-21T08:51:53.068773200Z",
     "start_time": "2024-01-21T08:51:53.020053200Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.SEX.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-21T08:51:53.142814400Z",
     "start_time": "2024-01-21T08:51:53.042089Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.SEX.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Pregnant females ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-21T08:51:53.490369Z",
     "start_time": "2024-01-21T08:51:53.068773200Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df[(df['SEX'] == 1)]['PREGNANT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-21T08:51:53.560228800Z",
     "start_time": "2024-01-21T08:51:53.213357600Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df[(df['SEX'] == 1)]['PREGNANT'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Pregnant males ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-21T08:51:53.569859100Z",
     "start_time": "2024-01-21T08:51:53.357183500Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df[(df['SEX'] == 2)]['PREGNANT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-21T08:51:53.724435300Z",
     "start_time": "2024-01-21T08:51:53.459309200Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df[(df['SEX'] == 2) & (df['PREGNANT'])]['PREGNANT'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-21T08:51:53.724435300Z",
     "start_time": "2024-01-21T08:51:53.603304Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['PREGNANT'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "It looks like 97 indicates males that aren't pregnant. In other words, for those values we can just input 2 instead of 97"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-21T08:51:53.725446400Z",
     "start_time": "2024-01-21T08:51:53.635440700Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['PREGNANT'].replace (97, 2, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Finally, 98 represents the females that are unknown to be pregnant or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-21T08:51:53.725446400Z",
     "start_time": "2024-01-21T08:51:53.658520400Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['PREGNANT'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can simply mark then as NA as the data is logically Not Available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-21T08:51:53.973687500Z",
     "start_time": "2024-01-21T08:51:53.690473600Z"
    }
   },
   "outputs": [],
   "source": [
    "df['PREGNANT'].replace(98, None, inplace = True)\n",
    "df['PREGNANT'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Most people aren't pregnant, this now makes a lot more sense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 1.5 ICU values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-21T08:51:53.976719900Z",
     "start_time": "2024-01-21T08:51:53.750798700Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.ICU.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-21T08:51:54.131596200Z",
     "start_time": "2024-01-21T08:51:53.786345200Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.crosstab(df['PATIENT_TYPE'], df['ICU'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "From the above we can see that the missing values of 97 are all corresponding to the values of PATIENT_TYPE = 1 which is for non hospitalized patients, while those of 99 are the missing values of the hospitalized patients, which again can not be told or predicted.\n",
    "\n",
    "So we can replace all the values of (97) with (2); since obviously patients who have never been hospitalized couldn't possibly be admitted to the ICU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-21T08:51:54.222751400Z",
     "start_time": "2024-01-21T08:51:54.002742900Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['ICU'].replace (97, 2, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-21T08:51:54.225697400Z",
     "start_time": "2024-01-21T08:51:54.039295200Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.ICU.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 1.6 INTUBED values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-21T08:51:54.300048800Z",
     "start_time": "2024-01-21T08:51:54.070550300Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.INTUBED.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-21T08:51:54.613362600Z",
     "start_time": "2024-01-21T08:51:54.096665100Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.crosstab(df['PATIENT_TYPE'], df['INTUBED'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Same logic of the ICU patients: patients that are intubed necessarily are also hospitalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-21T08:51:54.673016900Z",
     "start_time": "2024-01-21T08:51:54.278650300Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['INTUBED'].replace (97, 2, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-21T08:51:54.735650600Z",
     "start_time": "2024-01-21T08:51:54.307618700Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.INTUBED.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "We'll replace everything that we can't infer with NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-21T08:51:55.017755200Z",
     "start_time": "2024-01-21T08:51:54.340412100Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in [98, 99]:\n",
    "   df.replace(i , np.nan, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### How does the data look now ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-21T08:51:55.397975100Z",
     "start_time": "2024-01-21T08:51:54.740743100Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# First, let's temporarily reverse the step we did on \"DATE_DIED\" feature; as they are not really missing:\n",
    "df_null2 = df.copy()\n",
    "\n",
    "#Let's check again for our missing values:\n",
    "df_null2.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-21T08:51:57.506091500Z",
     "start_time": "2024-01-21T08:51:55.061718300Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.describe().round(3).T.drop('count', axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Looks much better already !\n",
    "What about a heatmap ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-21T08:51:57.556804Z",
     "start_time": "2024-01-21T08:51:57.414524Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# sns.heatmap(df_null2.isnull(), cbar=False)\n",
    "# plt.title('After Data cleanup', color = 'black', fontsize = 15)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-21T08:51:57.557806700Z",
     "start_time": "2024-01-21T08:51:57.442928900Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# fig, ax = plt.subplots(figsize=(20, 15))\n",
    "# mask=np.triu(np.ones_like(df.corr()))\n",
    "# sns.heatmap(df.corr(), mask = mask, annot = True, cmap = \"Blues\", vmin = -1, vmax = 1)\n",
    "# plt.title('Data Correlation', color = 'black', fontsize = 30)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.7 Hospitalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hospitalization is described by the `PATIENT_TYPE` column. It has a value of either 1: at home or 2: in hospital. We can change this column to a boolean column which, instead of describing the patient type, will describe if the patient is hospitalized or not. That means that we will have to change the column name to `HOSPITALIZED`, but we'll also have to invert all the values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-21T08:51:57.558797Z",
     "start_time": "2024-01-21T08:51:57.468550Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-21T08:51:57.981949100Z",
     "start_time": "2024-01-21T08:51:57.528772100Z"
    }
   },
   "outputs": [],
   "source": [
    "df[\"HOSPITALIZED\"] = [1 if i == 2 else 2 for i in df[\"PATIENT_TYPE\"]]\n",
    "df[[\"HOSPITALIZED\", \"PATIENT_TYPE\"]].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll drop the column as it is now redundant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-21T08:51:58.216378100Z",
     "start_time": "2024-01-21T08:51:57.877905400Z"
    }
   },
   "outputs": [],
   "source": [
    "df = df.drop(\"PATIENT_TYPE\", axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.8 Readability fix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the column names are not very readable, so we'll just fix that. In the original datasheet, it is said that the boolean values, 1 and 2, are actually \"Yes\" and \"No\" respectively. We'll just change that as well to make them boolean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-21T08:51:58.937787900Z",
     "start_time": "2024-01-21T08:51:58.088849Z"
    }
   },
   "outputs": [],
   "source": [
    "# Get columns whose data unique count is equal to 2 and are either 1, 2 or NA\n",
    "binary_cols = [col for col in df.columns if df[col].nunique() == 2 and df[col].dropna().value_counts().index.isin([1,2]).all()]\n",
    "binary_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number of boolean columns described in the datasheet is 15, but we have 16. The culprit is the `USMER` column, which does have only two values, but do not describe a boolean value. We'll just remove it from the list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-21T08:51:58.938791700Z",
     "start_time": "2024-01-21T08:51:58.820126800Z"
    }
   },
   "outputs": [],
   "source": [
    "binary_cols.remove(\"USMER\")\n",
    "binary_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a list of boolean value columns, we can change the values to strings of either \"Y\" or \"N\" and then change the column type to categorical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-21T08:51:59.018702900Z",
     "start_time": "2024-01-21T08:51:58.842375Z"
    }
   },
   "outputs": [],
   "source": [
    "# Change the values of the binary columns to \"Y\" if 1, \"N\" if 2\n",
    "# for col in binary_cols:\n",
    "#     df[col] = df[col].replace({1: \"Y\", 2: \"N\"})\n",
    "# df.describe().round(3).T.drop('count', axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.9 Categorizing the columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-21T08:51:59.271689700Z",
     "start_time": "2024-01-21T08:51:58.857424600Z"
    }
   },
   "outputs": [],
   "source": [
    "# For every columns, display the number of unique values\n",
    "df.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-21T08:52:01.743789900Z",
     "start_time": "2024-01-21T08:51:59.086858700Z"
    }
   },
   "outputs": [],
   "source": [
    "non_categorical = [\"AGE\"]\n",
    "categorical = df.columns.drop(non_categorical)\n",
    "\n",
    "for category in categorical:\n",
    "    df[category].astype(\"category\")\n",
    "    \n",
    "df.describe().round(3).T.drop('count', axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Dealing with null data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-21T08:52:02.010069500Z",
     "start_time": "2024-01-21T08:52:01.742802800Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Select only the categorical columns from the DataFrame\n",
    "categorical_data = df[categorical]\n",
    "\n",
    "# Count the total number of rows in the categorical_data DataFrame\n",
    "total_rows = len(categorical_data)\n",
    "\n",
    "# Count the number of null values in each categorical column\n",
    "null_rows_count = categorical_data.isnull().sum()\n",
    "\n",
    "# Calculate the percentage of null values for each column\n",
    "percentage_null_values = (null_rows_count / total_rows) * 100\n",
    "\n",
    "# Create a DataFrame to display the results\n",
    "null_summary = pd.DataFrame({\n",
    "    'Null Values Count': null_rows_count,\n",
    "    'Total Values Count': total_rows,\n",
    "    'Percentage of Null Values': percentage_null_values\n",
    "})\n",
    "\n",
    "# Print the summary\n",
    "print(\"Summary of null values in each categorical column:\")\n",
    "print(null_summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-21T08:52:02.363782300Z",
     "start_time": "2024-01-21T08:52:01.984485300Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Calculate the initial number of rows\n",
    "initial_rows = len(categorical_data)\n",
    "\n",
    "# Remove rows with null values\n",
    "categorical_data_cleaned = categorical_data.dropna()\n",
    "\n",
    "# Calculate the number of removed lines\n",
    "removed_lines = initial_rows - len(categorical_data_cleaned)\n",
    "\n",
    "# Calculate the number of lines that remain after removal\n",
    "remaining_lines = len(categorical_data_cleaned)\n",
    "\n",
    "# Print the number of removed lines and remaining lines\n",
    "print(f\"Number of removed lines: {removed_lines}\")\n",
    "print(f\"Number of lines remaining: {remaining_lines}\")\n",
    "\n",
    "# Optionally, you can assign the cleaned DataFrame to a new variable or overwrite the original one\n",
    "# categorical_data = categorical_data_cleaned\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-21T08:52:02.365779900Z",
     "start_time": "2024-01-21T08:52:02.354027300Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Calculate the number of rows to export (10% of the total cleaned data)\n",
    "# percentage_to_export = 0.1\n",
    "# num_rows_to_export = int(len(categorical_data_cleaned) * percentage_to_export)\n",
    "\n",
    "# Set a random seed for reproducibility\n",
    "# random_seed = 42  # You can use any integer as the seed\n",
    "\n",
    "# Use the sample method to randomly select the specified number of rows\n",
    "# random_subset = categorical_data_cleaned.sample(n=num_rows_to_export, random_state=random_seed)\n",
    "\n",
    "# Specify the path where you want to save the cleaned subset of data to a CSV file\n",
    "# cleaned_subset_output_file = \"cleaned_categorical_data_subset.csv\"\n",
    "\n",
    "# Export the cleaned subset of data to a CSV file\n",
    "# random_subset.to_csv(cleaned_subset_output_file, index=False)\n",
    "\n",
    "# Optionally, you can read the cleaned subset data back into a DataFrame if needed\n",
    "# cleaned_subset_df = pd.read_csv(cleaned_subset_output_file)\n",
    "\n",
    "# Display the first few rows of the cleaned subset DataFrame\n",
    "# print(\"\\nFirst few rows of the cleaned subset DataFrame:\")\n",
    "# print(cleaned_subset_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Replacing the 1, 2 values with 1, 0 respectively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.replace({2: 0})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Looking for correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-21T08:52:03.864444400Z",
     "start_time": "2024-01-21T08:52:02.364803100Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.corr()['DEAD']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-21T08:52:06.190756900Z",
     "start_time": "2024-01-21T08:52:03.869440700Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(20, 15))\n",
    "sorted_corr = df.copy()\n",
    "sorted_corr = sorted_corr.corr()[['DEAD']].sort_values(by='DEAD', ascending=False)\n",
    "\n",
    "sns.heatmap(sorted_corr, annot = True, cmap = \"Blues\", vmin = -1, vmax = 1)\n",
    "plt.title('Death factors correlation', color = 'black', fontsize = 30)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-21T08:52:08.303771500Z",
     "start_time": "2024-01-21T08:52:06.099050100Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sorted_corr_relevant = df.copy()\n",
    "correlation_matrix = sorted_corr_relevant.corr()[['DEAD']]\n",
    "\n",
    "filtered_corr = correlation_matrix[(correlation_matrix > 0.1) | (correlation_matrix < -0.1)].dropna()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(20, 15))\n",
    "\n",
    "sns.heatmap(filtered_corr.sort_values(by='DEAD', ascending=False), annot=True, cmap=\"Blues\", vmin=-1, vmax=1)\n",
    "plt.title('Death factors correlation', color='black', fontsize=30)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Decision tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Basic example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-21T08:52:09.106088600Z",
     "start_time": "2024-01-21T08:52:08.282548900Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "X = df.copy().drop('DEAD', axis=1)\n",
    "Y = df['DEAD']\n",
    "\n",
    "X = X.fillna(X.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-21T08:52:19.987338900Z",
     "start_time": "2024-01-21T08:52:08.909644800Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.30, random_state=42)\n",
    "\n",
    "dtree = DecisionTreeClassifier()\n",
    "dtree = dtree.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-21T08:52:22.476504700Z",
     "start_time": "2024-01-21T08:52:20.089829Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"Decision Tree Train Accuracy: \", dtree.score(x_train,y_train), \"\\n\")\n",
    "print(\"Decision Tree Test Accuracy:\", dtree.score(x_test, y_test), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-21T08:52:23.469676Z",
     "start_time": "2024-01-21T08:52:22.472873700Z"
    }
   },
   "outputs": [],
   "source": [
    "y_pred = dtree.predict(x_test)\n",
    "ConfusionMatrixDisplay.from_predictions(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtree_report = pd.DataFrame.from_dict(classification_report(y_test, y_pred, target_names = [\"Deadn't\", \"Dead\"], output_dict=True)).T\n",
    "dtree_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Correlation based Tree data selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Here I just select the more relevant columns based on the correlation results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-21T09:04:16.959924200Z",
     "start_time": "2024-01-21T09:04:16.773255300Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bound = 0.4\n",
    "sorted_corr.sort_values(by='DEAD', ascending=False)\n",
    "filtered_corr = sorted_corr[(sorted_corr['DEAD'] > bound) | (sorted_corr['DEAD'] < -bound)]\n",
    "filtered_corr.sort_values(by='DEAD', ascending=False)\n",
    "unique_names = filtered_corr.index.tolist()\n",
    "unique_names.remove('DEAD')\n",
    "unique_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-21T09:04:19.763632900Z",
     "start_time": "2024-01-21T09:04:19.634568400Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_corr = X[unique_names].copy()\n",
    "Y_corr = Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-21T09:04:22.447972400Z",
     "start_time": "2024-01-21T09:04:21.567621200Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_train_corr, x_test_corr, y_train_corr, y_test_corr = train_test_split(X_corr, Y_corr, test_size=0.30, random_state=42)\n",
    "\n",
    "dtree_corr = DecisionTreeClassifier()\n",
    "dtree_corr = dtree_corr.fit(x_train_corr, y_train_corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-21T09:04:24.636073700Z",
     "start_time": "2024-01-21T09:04:24.226529100Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"Decision Tree Train Accuracy: \", dtree_corr.score(x_train_corr, y_train_corr), \"\\n\")\n",
    "print(\"Decision Tree Train Accuracy:\", dtree_corr.score(x_test_corr, y_test_corr), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-21T09:04:30.916806Z",
     "start_time": "2024-01-21T09:04:30.173157900Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tree.plot_tree(dtree_corr, feature_names=X_corr.columns, filled=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-21T09:18:03.614381200Z",
     "start_time": "2024-01-21T09:18:02.758475800Z"
    }
   },
   "outputs": [],
   "source": [
    "y_pred_corr = dtree_corr.predict(x_test_corr)\n",
    "ConfusionMatrixDisplay.from_predictions(y_test_corr, y_pred_corr, cmap=\"Blues\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtree_corr_report = pd.DataFrame.from_dict(classification_report(y_test_corr, y_pred_corr, target_names = [\"Deadn't\", \"Dead\"], output_dict=True)).T\n",
    "dtree_corr_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-21T09:23:50.531634400Z",
     "start_time": "2024-01-21T09:20:14.285533300Z"
    }
   },
   "outputs": [],
   "source": [
    "random_forest = RandomForestClassifier()\n",
    "random_forest = random_forest.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-21T09:25:03.463100100Z",
     "start_time": "2024-01-21T09:24:18.387662800Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Random Forest Train Accuracy: \", random_forest.score(x_train,y_train), \"\\n\")\n",
    "print(\"Random Forest Test Accuracy:\", random_forest.score(x_test, y_test), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-21T09:29:51.491523600Z",
     "start_time": "2024-01-21T09:29:37.950799300Z"
    }
   },
   "outputs": [],
   "source": [
    "y_pred = random_forest.predict(x_test)\n",
    "c_matrix = confusion_matrix(y_test, y_pred)\n",
    "ConfusionMatrixDisplay.from_predictions(y_test, y_pred, cmap=\"Blues\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-21T09:34:04.980211300Z",
     "start_time": "2024-01-21T09:34:04.798457900Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "TP, FN, FP, TN = c_matrix.ravel()\n",
    "print(TP, FN, FP, TN) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-21T09:36:58.875186800Z",
     "start_time": "2024-01-21T09:36:58.762288Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "N, P = y_test.value_counts().ravel()\n",
    "print(N, P)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-21T09:37:08.469357800Z",
     "start_time": "2024-01-21T09:37:08.400605900Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "error_rate = (FP+FN)/(P+N)\n",
    "error_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-21T09:37:13.728421Z",
     "start_time": "2024-01-21T09:37:13.705553200Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "accuracy = 1 - error_rate\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest_report = pd.DataFrame.from_dict(classification_report(y_test, y_pred, target_names = [\"Deadn't\", \"Dead\"], output_dict=True)).T\n",
    "forest_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forest with most correlated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest_corr = RandomForestClassifier()\n",
    "forest_corr = forest_corr.fit(x_train_corr, y_train_corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Random Forest Train Accuracy: \", forest_corr.score(x_train_corr, y_train_corr), \"\\n\")\n",
    "print(\"Random Forest Test Accuracy:\", forest_corr.score(x_test_corr, y_test_corr), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_corr = forest_corr.predict(x_test_corr)\n",
    "ConfusionMatrixDisplay.from_predictions(y_test_corr, y_pred_corr, cmap=\"Blues\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest_corr_report = pd.DataFrame.from_dict(classification_report(y_test_corr, y_pred_corr, target_names = [\"Deadn't\", \"Dead\"], output_dict=True)).T\n",
    "forest_corr_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(solver=\"saga\")\n",
    "\n",
    "lr.fit(x_train,y_train)\n",
    "print(\"Logistic Regression Train Accuracy: \", lr.score(x_train,y_train), \"\\n\")\n",
    "print(\"Logistic Regression Test Accuracy: \", lr.score(x_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = lr.predict(x_test)\n",
    "lr_report = pd.DataFrame.from_dict(classification_report(y_test, y_pred, target_names = [\"Deadn't\", \"Dead\"], output_dict=True)).T\n",
    "lr_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reports = {\n",
    "    \"Decision Tree\": dtree_report, \n",
    "    \"Decision Tree (corr)\": dtree_corr_report, \n",
    "    \"Random Forest\": forest_report, \n",
    "    \"Random Forest (corr)\": forest_corr_report, \n",
    "    \"Logistic Regression\": lr_report\n",
    "}\n",
    "attributes = {\n",
    "    \"Precision dead\": (\"precision\", \"Dead\"), \n",
    "    \"Recall dead\": (\"recall\", \"Dead\"), \n",
    "    \"Precision deadn't\": (\"precision\", \"Deadn't\"),\n",
    "    \"Recall deadn't\": (\"recall\", \"Deadn't\"), \n",
    "    \"Accuracy\": (\"f1-score\", \"accuracy\")\n",
    "}\n",
    "\n",
    "values = {}\n",
    "\n",
    "for attribute, index in attributes.items():\n",
    "    if not attribute in values:\n",
    "        values[attribute] = []\n",
    "    for report_value in reports.values():\n",
    "        values[attribute].append(round(report_value[index[0]][index[1]] * 100, 2))\n",
    "\n",
    "x = np.arange(len(reports.keys()))  # the label locations\n",
    "width = 0.1  # the width of the bars\n",
    "multiplier = 0\n",
    "\n",
    "fig, ax = plt.subplots(layout='constrained')\n",
    "fig.set_figwidth(10)\n",
    "\n",
    "for attribute, measurement in values.items():\n",
    "    offset = width * multiplier\n",
    "    rects = ax.bar(x + offset, measurement, width, label=attribute)\n",
    "    ax.bar_label(rects, padding=1)\n",
    "    multiplier += 1\n",
    "\n",
    "# Add some text for labels, title and custom x-axis tick labels, etc.\n",
    "ax.set_ylabel('Percentage (%)')\n",
    "ax.set_title('Report score per model')\n",
    "ax.set_xticks(x + width, reports.keys())\n",
    "ax.legend(loc='upper left', ncols=3)\n",
    "ax.set_ylim(0, 130)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jeannine = pd.Series([\n",
    "    0,          # USMER\n",
    "    12,         # MEDICAL_UNIT\n",
    "    1,          # SEX\n",
    "    0,          # INTUBED\n",
    "    1,          # PNEUMONIA\n",
    "    64,         # AGE\n",
    "    0,          # PREGNANT\n",
    "    1,          # DIABETES\n",
    "    0,          # COPD\n",
    "    0,          # ASTHMA\n",
    "    1,          # INMSUPR\n",
    "    1,          # HIPERTENSION\n",
    "    1,          # OTHER_DISEASE\n",
    "    0,          # CARDIOVASCULAR\n",
    "    1,          # OBESITY\n",
    "    1,          # RENAL_CHRONIC\n",
    "    1,          # TOBACCO\n",
    "    3,          # CLASIFFICATION_FINAL\n",
    "    0,          # ICU\n",
    "    0,          # HOPSITALIZED\n",
    "], index=X.columns)\n",
    "jeannine = jeannine.to_frame().T\n",
    "\n",
    "for category in categorical:\n",
    "    if category == \"DEAD\":\n",
    "        continue\n",
    "    jeannine[category].astype(\"category\")\n",
    "\n",
    "jeannine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jeannine_corr = jeannine[unique_names]\n",
    "jeannine_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "j_pred = {\n",
    "    \"dtree\": dtree.predict(jeannine)[0],\n",
    "    \"dtree_corr\": dtree_corr.predict(jeannine_corr)[0],\n",
    "    \"forest\": random_forest.predict(jeannine)[0],\n",
    "    \"forest_corr\": forest_corr.predict(jeannine_corr)[0],\n",
    "    \"lr\": lr.predict(jeannine)[0]\n",
    "}\n",
    "\n",
    "print(j_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
